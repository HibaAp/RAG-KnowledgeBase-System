{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ollama in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.4.7)\n",
      "Requirement already satisfied: httpx<0.29,>=0.27 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ollama) (0.27.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ollama) (2.10.4)\n",
      "Requirement already satisfied: anyio in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<0.29,>=0.27->ollama) (4.4.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<0.29,>=0.27->ollama) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<0.29,>=0.27->ollama) (1.0.5)\n",
      "Requirement already satisfied: idna in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<0.29,>=0.27->ollama) (3.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<0.29,>=0.27->ollama) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpcore==1.*->httpx<0.29,>=0.27->ollama) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (4.12.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "response=ollama.chat(model=\"deepseek-r1:1.5b\",messages=[{\"role\":\"user\",\"content\":\"Hai\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Message(role='assistant', content='<think>\\n\\n</think>\\n\\nHello! How can I assist you today? ðŸ˜Š', images=None, tool_calls=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"message\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_api_key = \"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\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.3.14)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.3.14)\n",
      "Requirement already satisfied: pdfplumber in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.11.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.9.0.post1)\n",
      "Requirement already satisfied: requests in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: langchain-groq in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.2.3)\n",
      "Requirement already satisfied: googlesearch-python in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: langchain-experimental in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.3.4)\n",
      "Requirement already satisfied: sentence_transformers in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.3.1)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (3.11.11)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.29 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (0.3.29)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (0.3.5)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (0.2.10)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (2.10.4)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (8.4.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-community) (2.7.1)\n",
      "Requirement already satisfied: pdfminer.six==20231228 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pdfplumber) (20231228)\n",
      "Requirement already satisfied: Pillow>=9.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pdfplumber) (10.4.0)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pdfplumber) (4.30.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pdfminer.six==20231228->pdfplumber) (3.3.2)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pdfminer.six==20231228->pdfplumber) (42.0.8)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.14.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\admin\\appdata\\roaming\\python\\python312\\site-packages (from faiss-cpu) (24.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (2024.12.14)\n",
      "Requirement already satisfied: groq<1,>=0.4.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-groq) (0.13.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from beautifulsoup4) (2.6)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence_transformers) (4.47.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence_transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence_transformers) (2.4.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence_transformers) (0.27.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.24.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (0.27.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (4.12.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2024.9.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (1.33)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith<0.3,>=0.1.17->langchain) (3.10.13)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (3.4.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (72.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\appdata\\roaming\\python\\python312\\site-packages (from tqdm->sentence_transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.7.24)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.5.1)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.16.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain) (3.0.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install langchain langchain-community pdfplumber numpy scikit-learn faiss-cpu requests langchain-groq googlesearch-python beautifulsoup4 langchain-experimental sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains.hyde.base import HypotheticalDocumentEmbedder\n",
    "from langchain.llms import Ollama\n",
    "# Monkey-patch with proper input_variables access\n",
    "@property\n",
    "def fixed_input_keys(self) -> List[str]:\n",
    "    return self.llm_chain.prompt.input_variables  # Access through prompt\n",
    "\n",
    "HypotheticalDocumentEmbedder.input_keys = fixed_input_keys\n",
    "\n",
    "def get_retrievers(pdf_path, groq_api_key):\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    import random\n",
    "    import pdfplumber\n",
    "    import numpy as np\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "    from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "    from langchain_community.document_loaders import PyPDFLoader\n",
    "    from langchain.docstore.document import Document\n",
    "    from langchain_community.vectorstores import FAISS\n",
    "\n",
    "    # Initialize HyDE components\n",
    "    hyde_prompt = PromptTemplate(\n",
    "        input_variables=[\"question\"],\n",
    "        template=\"\"\"Generate a comprehensive hypothetical answer to: {question}\n",
    "    Include key facts, concepts, and relevant context.\"\"\"\n",
    "    )\n",
    "\n",
    "    hyde_llm = Ollama(\n",
    "        model=\"deepseek-r1:1.5b\"\n",
    "    )\n",
    "    hyde_chain = LLMChain(llm=hyde_llm, prompt=hyde_prompt)\n",
    "\n",
    "    # Base embeddings model\n",
    "    embedding_model = HuggingFaceBgeEmbeddings(\n",
    "        model_name=\"BAAI/bge-large-en\",\n",
    "        encode_kwargs={'normalize_embeddings': False}\n",
    "    )\n",
    "\n",
    "    # Wrap with HyDE (using patched version)\n",
    "    hyde_embeddings = HypotheticalDocumentEmbedder(\n",
    "        llm_chain=hyde_chain,\n",
    "        base_embeddings=embedding_model,\n",
    "    )\n",
    "    def embed_texts(texts):\n",
    "        return embedding_model.embed_documents(texts)\n",
    "\n",
    "\n",
    "    def get_header_footer(pdf_path, threshold=0.71):\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            total_pages = len(pdf.pages)\n",
    "            if total_pages >= 15:\n",
    "                random_page_nos = random.sample(range(5, total_pages), 10)\n",
    "            else:\n",
    "                random_page_nos = list(range(total_pages))\n",
    "\n",
    "            avg_similarity = 1\n",
    "            header_lines = -1\n",
    "            while avg_similarity > threshold and header_lines < 4:\n",
    "                header_lines += 1\n",
    "                five_lines = []\n",
    "                for page_no in random_page_nos:\n",
    "                    lines = pdf.pages[page_no].extract_text().split('\\n')\n",
    "                    if len(lines) > header_lines:\n",
    "                        five_lines.append(lines[header_lines])\n",
    "                similarities = cosine_similarity(embed_texts(five_lines))\n",
    "                avg_similarity = np.mean(similarities[np.triu_indices(len(similarities), k=1)])\n",
    "\n",
    "            avg_similarity = 1\n",
    "            footer_lines = -1\n",
    "            while avg_similarity > threshold and footer_lines < 4:\n",
    "                footer_lines += 1\n",
    "                five_lines = []\n",
    "                for page_no in random_page_nos:\n",
    "                    lines = pdf.pages[page_no].extract_text().split('\\n')\n",
    "                    if len(lines) > footer_lines:\n",
    "                        five_lines.append(lines[-(footer_lines + 1)])\n",
    "                similarities = cosine_similarity(embed_texts(five_lines))\n",
    "                avg_similarity = np.mean(similarities[np.triu_indices(len(similarities), k=1)])\n",
    "            return header_lines, footer_lines\n",
    "\n",
    "\n",
    "    def extract_text(pdf_path):\n",
    "        header_lines, footer_lines = get_header_footer(pdf_path)\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            text = ''\n",
    "            for page in pdf.pages:\n",
    "                page_text = page.extract_text()\n",
    "                if page_text:\n",
    "                    lines = page_text.split('\\n')\n",
    "                    if lines:\n",
    "                        page_text = '\\n'.join(lines[header_lines:-(footer_lines + 1)])\n",
    "                        text += page_text + '\\n'\n",
    "            return text\n",
    "\n",
    "    text = extract_text(pdf_path)\n",
    "\n",
    "    def get_vectorstore1():\n",
    "        texts = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200).split_text(text)\n",
    "        docs = [Document(text) for text in texts if text.strip()]\n",
    "        vectorstore = FAISS.from_documents(docs, hyde_embeddings)  # Use HyDE embeddings\n",
    "        return vectorstore\n",
    "\n",
    "    def get_vectorstore2():\n",
    "        texts = RecursiveCharacterTextSplitter(chunk_size=6000, chunk_overlap=400).split_text(text)\n",
    "        docs = [Document(text) for text in texts if text.strip()]\n",
    "        vectorstore = FAISS.from_documents(docs, hyde_embeddings)  # Use HyDE embeddings\n",
    "        return vectorstore\n",
    "\n",
    "    retriever1 = get_vectorstore1().as_retriever(search_kwargs={\"k\": 6})\n",
    "    retriever2 = get_vectorstore2().as_retriever(search_kwargs={\"k\": 3})\n",
    "    return retriever1, retriever2\n",
    "\n",
    "def web_search(query, max_results=3):\n",
    "    \"\"\"Perform web search using googlesearch-python\"\"\"\n",
    "    from googlesearch import search\n",
    "    results = list(search(query, num_results=max_results))\n",
    "    return results[:max_results]\n",
    "\n",
    "def fetch_content_from_link(link):\n",
    "    try:\n",
    "        if not link.startswith(('http://', 'https://')):\n",
    "            link = f'https://{link}'\n",
    "        response = requests.get(link, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        raw_text = soup.get_text()\n",
    "        cleaned_text = ' '.join(raw_text.split())\n",
    "        return cleaned_text\n",
    "    except Exception as e:\n",
    "        #print(f\"Error fetching {link}: {str(e)}\")\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "\n",
    "def get_answer(query, retriever1, retriever2, groq_api_key):\n",
    "    # Web search integration\n",
    "    links = web_search(query)\n",
    "    web_results = \"\\n\".join([f\"{i+1}. {fetch_content_from_link(link)}\" for i, link in enumerate(links)])\n",
    "\n",
    "    # HyDE-enhanced document retrieval\n",
    "    doc_results1 = retriever1.get_relevant_documents(query)\n",
    "    doc_results2 = retriever2.get_relevant_documents(query)\n",
    "    doc_context = \"\\n---\\n\".join([doc.page_content for doc in doc_results1 + doc_results2])\n",
    "\n",
    "    # Context management\n",
    "    combined_context = f\"\"\"\n",
    "    WEB SEARCH RESULTS:\n",
    "    {web_results}\n",
    "\n",
    "    DOCUMENT CONTENT:\n",
    "    {doc_context}\n",
    "    \"\"\"\n",
    "    if len(combined_context) > 4000:\n",
    "        combined_context = combined_context[:4000]\n",
    "\n",
    "    # LLM initialization\n",
    "    llm = Ollama(\n",
    "        model=\"deepseek-re:1.5b\"\n",
    "    )\n",
    "\n",
    "    # Corrected prompt template\n",
    "    prompt_template = \"\"\"\n",
    "    Analyze and synthesize information from both web results and document content to answer\n",
    "    the question. Follow these steps:\n",
    "    1. Identify key facts from web results.\n",
    "    2. Find supporting information in documents.\n",
    "    3. Combine insights from both sources.\n",
    "    4. If sources conflict, note this and prioritize document content.\n",
    "    5. Provide a clear, concise answer.\n",
    "    6. Do not restate the question. Provide a direct comparison of the answers.\n",
    "    7. Give a final judgment on which answer is better and why, without using phrases like 'based on web results' or unnecessary explanations.\n",
    "\n",
    "    CONTEXT:\n",
    "    {combined_context}\n",
    "\n",
    "    QUESTION: {question}\n",
    "\n",
    "    FINAL ANSWER:\n",
    "    \"\"\"\n",
    "    prompt = PromptTemplate(\n",
    "        template=prompt_template,\n",
    "        input_variables=[\"combined_context\", \"question\"]  # Fixed placeholder reference\n",
    "    )\n",
    "\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "    return chain.run(combined_context=combined_context, question=query)  # Matching argument names\n",
    "\n",
    "\n",
    "def compare_answers(query, retriever1, retriever2, retriever3, retriever4, groq_api_key):\n",
    "    answer1 = get_answer(query, retriever1, retriever2, groq_api_key)\n",
    "    answer2 = get_answer(query, retriever3, retriever4, groq_api_key)\n",
    "\n",
    "    comparison_prompt = f\"\"\"\n",
    "    Compare the two answers given for the same question:\n",
    "\n",
    "    QUESTION: {query}\n",
    "\n",
    "    ANSWER 1: {answer1}\n",
    "\n",
    "    ANSWER 2: {answer2}\n",
    "\n",
    "    Do not restate the question. Provide a direct comparison of the answers focusing only on:\n",
    "    1. Factual consistency\n",
    "    2. Source reliability\n",
    "    3. Completeness of information\n",
    "    4. Clarity of presentation\n",
    "\n",
    "    Give a final judgment on which answer is better and why, without using phrases like 'based on web results' or unnecessary explanations.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    llm = Ollama(\n",
    "        model=\"deepseek-r1:1.5b\"\n",
    "    )\n",
    "\n",
    "    return llm.invoke(comparison_prompt).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so I need to figure out the benefits of AI in healthcare based on this detailed response from someone else. Let me read through it again.\n",
      "\n",
      "First, they mentioned personalized treatment plans. That makes sense because AI can analyze a lot of data about a patient's symptoms and medical history. So, it tailors treatments to each individual's unique needs. But I wonder how exactly that worksâ€”like what kind of data is considered? Maybe things like genetic information or lifestyle factors?\n",
      "\n",
      "Next, predicting diseases. They talk about early detection through machine learning models. That rings a bell. I've heard about breast cancer screening using AI. I should check if these predictions are accurate and when they can be used, maybe before the disease actually shows up.\n",
      "\n",
      "Then, optimizing care delivery. So, AI helps plan treatment schedules. Maybe it uses AI to simulate different scenarios or recommend drugs that fit each patient's needs. This could make care more efficient by reducing waiting times or improving outcomes.\n",
      "\n",
      "They also mention reducing medical errors. By automating certain tasks and having redundant data points, errors in diagnosis or medication are minimized. That's something I've seen mentioned before; it would be a big plus in healthcare settings where errors can lead to serious consequences.\n",
      "\n",
      "The response then talks about ethical concerns, like patient privacy. AI systems have to handle sensitive information carefully. They mention transparency issuesâ€”like why the system makes certain decisions and how it could potentially act on patients' data. I think this is important because healthcare relies heavily on trust.\n",
      "\n",
      "Data sharing and interoperability are also key points. Patients often share health data across different systems, but having a unified AI that works across all these platforms is crucial for consistency and effectiveness.\n",
      "\n",
      "In terms of broader impacts, global healthcare systems would see improvements in treatment outcomes and patient satisfaction. Plus, AI could revolutionize diagnostics by making tests more personalized or automated, which might reduce costs and the need for physical visits.\n",
      "\n",
      "Lastly, they talk about research potential. Areas like precision medicine are expanding, where treatments are tailored to specific genetic markers. This could be a future focus area for medical advancements.\n",
      "\n",
      "Wait, I should make sure these points are accurate. For example, how exactly do AI systems detect diseases before it's obvious? Maybe they analyze biomarkers or wearable devices. Also, is there any mention of how the accuracy of disease prediction models is proven or how effective their predictions are in practice?\n",
      "\n",
      "I also wonder about the role of transparency. If an AI system makes a decision without clear guidelines, patients might not trust it. So, being transparent and having some accountability mechanism would be important.\n",
      "\n",
      "Another point is whether these benefits apply across all types of healthcareâ€”like hospitals, clinics, etc., or if they are more pronounced in certain settings. For instance, does AI work better in intensive care units where the volume is higher?\n",
      "\n",
      "I should also consider the technology stack involved. Do they mention specific AI models used, like deep learning for disease prediction? And what about ethical dilemmas like bias in algorithms affecting treatment decisions? That's a big topic in healthcare and could impact the fairness of AI systems.\n",
      "\n",
      "Overall, I think the response covers most aspects well but might need some additional details on specific technologies or methodologies. For example, how exactly are diseases being predicted before they appear (like in breast cancer screening), or what types of medical data are analyzed for personalized treatment plans.\n",
      "\n",
      "I should also check if there's anything about patient outcomesâ€”like how many patients benefit from AI-driven treatments and whether these treatments lead to better management of chronic conditions. Maybe some studies showing long-term benefits after implementation?\n",
      "\n",
      "In terms of ethical implications, I should address issues like patient privacy protection, data ownership, and the potential misuse of AI in healthcare. For instance, could an AI system be used to diagnose diseases that are otherwise classified as benign or non-infectious? That would require clear guidelines.\n",
      "\n",
      "Also, the broader impact on global healthcare systemsâ€”would these benefits translate across regions with different medical practices and policies? How do institutions cooperate on using AI in their care delivery?\n",
      "\n",
      "Lastly, any mention of future directions? Like advancements in explainable AI, ethical frameworks for AI governance, or collaboration between ethicists and technologists to ensure responsible use.\n",
      "\n",
      "So, in summary, the comprehensive answer includes data-driven insights into how AI is making healthcare more personalized, predictive, efficient, and ethical. It also outlines the broader impacts on patient care, healthcare systems, and future research directions.\n",
      "</think>\n",
      "\n",
      "**Comprehensive Overview of AI's Benefits in Healthcare**\n",
      "\n",
      "1. **Personalized Treatment Plans**\n",
      "   - AI analyzes comprehensive datasets including genetic information, lifestyle factors, and medical history to tailor treatment plans, optimizing outcomes by addressing individual needs.\n",
      "\n",
      "2. **Early Disease Detection**\n",
      "   - Machine learning models process biomarkers and wearable data to predict disease onset, enabling early detection (e.g., breast cancer screening) with high accuracy.\n",
      "\n",
      "3. **Optimizing Care Delivery**\n",
      "   - AI simulates treatment scenarios, recommends drugs, and reduces waiting times, enhancing efficiency and patient satisfaction in healthcare settings.\n",
      "\n",
      "4. **Reduction of Medical Errors**\n",
      "   - Automation of diagnostic tasks minimizes errors, crucial for serious consequences like cancer progression, ensuring accurate diagnosis before disease onset.\n",
      "\n",
      "5. **Transparency and Accountability**\n",
      "   - AI systems explain decision-making processes, addressing trust issues and accountability mechanisms to build patient confidence in outcomes.\n",
      "\n",
      "6. **Global Healthcare Improvement**\n",
      "   - Across regions, AI improves treatment outcomes and patient satisfaction, particularly in intensive care units with high volume data analysis.\n",
      "\n",
      "7. **Broad Health Impact**\n",
      "   - Enhances diagnostic accuracy and treatment efficiency, revolutionizing personalized medicine for precision in genetic markers, a future focus area.\n",
      "\n",
      "8. **Ethical Considerations**\n",
      "   - Transparency, data ownership, and privacy protection are critical; ethical guidelines ensure fairness and accountability in AI-driven decisions.\n",
      "\n",
      "9. **Technological Stack and Models**\n",
      "   - Utilizes deep learning models for disease prediction and personalized treatment planning, with ongoing research to refine algorithms and methodologies.\n",
      "\n",
      "10. **Future Directions**\n",
      "    - Advancements in explainable AI and responsible governance aim to enhance ethical use of AI in healthcare, ensuring its responsible deployment and collaboration between ethicists and technologists.\n",
      "\n",
      "This comprehensive approach highlights AI's transformative potential in healthcare, addressing both immediate benefits and broader societal implications, from individual patient outcomes to global health systems.\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import Ollama\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Define the prompt template\n",
    "hyde_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"\"\"Generate a comprehensive hypothetical answer to: {question}\n",
    "    Include key facts, concepts, and relevant context.\"\"\"\n",
    ")\n",
    "\n",
    "# Use Ollama for local inference\n",
    "hyde_llm = Ollama(model=\"deepseek-r1:1.5b\")\n",
    "\n",
    "# Create the chain\n",
    "hyde_chain = LLMChain(llm=hyde_llm, prompt=hyde_prompt)\n",
    "\n",
    "# Example usage\n",
    "question = \"What are the benefits of AI in healthcare?\"\n",
    "response = hyde_chain.run(question)\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
