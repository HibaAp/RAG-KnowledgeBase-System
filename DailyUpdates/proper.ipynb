{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains.hyde.base import HypotheticalDocumentEmbedder\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.docstore.document import Document\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pdfplumber\n",
    "import random\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from googlesearch import search\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.output_parsers import PydanticOutputParser, PydanticToolsParser\n",
    "import chardet\n",
    "import re\n",
    "from io import BytesIO\n",
    "from docx import Document as DocxDocument\n",
    "\n",
    "def extract_text_from_pdf(pdf_path: str) -> str:\n",
    "    \"\"\"Extract text from a PDF, removing headers and footers.\"\"\"\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        text = '\\n'.join([page.extract_text() for page in pdf.pages if page.extract_text()])\n",
    "    return text\n",
    "\n",
    "def embed_texts(texts: List[str]) -> np.ndarray:\n",
    "    \"\"\"Embed a list of texts using HuggingFace embeddings.\"\"\"\n",
    "    embedding_model = HuggingFaceBgeEmbeddings(model_name=\"BAAI/bge-large-en\", encode_kwargs={'normalize_embeddings': False})\n",
    "    return embedding_model.embed_documents(texts)\n",
    "\n",
    "def create_vector_store_from_pdf(pdf_path: str):\n",
    "    \"\"\"Create a FAISS vector store from a given PDF.\"\"\"\n",
    "    text = extract_text_from_pdf(pdf_path)\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "    texts = text_splitter.split_text(text)\n",
    "    documents = [Document(page_content=chunk) for chunk in texts]\n",
    "    embedding_model = HuggingFaceBgeEmbeddings(model_name=\"BAAI/bge-large-en\", encode_kwargs={'normalize_embeddings': False})\n",
    "    vector_store = FAISS.from_documents(documents, embedding_model)\n",
    "    return vector_store\n",
    "\n",
    "def retrieve(query: str, pdf_path: str):\n",
    "    \"\"\"Retrieve relevant documents from the vector store created from the given PDF.\"\"\"\n",
    "    vector_store = create_vector_store_from_pdf(pdf_path)\n",
    "    embedding_model = HuggingFaceBgeEmbeddings(model_name=\"BAAI/bge-large-en\", encode_kwargs={'normalize_embeddings': False})\n",
    "    encoded_query = embedding_model.embed_query(query)\n",
    "    return vector_store.similarity_search_by_vector(encoded_query, k=5)\n",
    "\n",
    "class SubQuery(BaseModel):\n",
    "    \"\"\"Extracts multiple sub-queries from a user query for retrieval.\"\"\"\n",
    "    sub_queries: list[str] = Field(..., description=\"List of highly specific database queries.\")\n",
    "\n",
    "def retrieve_results(query: str, pdf_path: str):\n",
    "    \"\"\"Converts a user query into sub-queries and retrieves relevant documents.\"\"\"\n",
    "    system_prompt = \"\"\"You are an expert at query decomposition.\n",
    "    Your task is to break a user question into multiple highly specific sub-queries\n",
    "    that must be answered to fully respond to the original question.\n",
    "    Ensure sub-queries are specific and relevant to the context.\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ])\n",
    "\n",
    "    llm = ChatGroq(groq_api_key=groq_api_key, model=\"llama3-70b-8192\", temperature=0.05)\n",
    "    llm_with_tools = llm.bind_tools([SubQuery])\n",
    "    parser = PydanticToolsParser(tools=[SubQuery])\n",
    "    query_analyzer = prompt | llm_with_tools | parser\n",
    "    response = query_analyzer.invoke({\"question\": query})\n",
    "\n",
    "    sub_queries = []\n",
    "    for item in response:\n",
    "        sub_queries.extend(item.sub_queries)\n",
    "\n",
    "    results = {}\n",
    "    for sub_query in sub_queries:\n",
    "        retrieved_docs = retrieve(sub_query, pdf_path)  # Call the retrieval function\n",
    "        results[sub_query] = retrieved_docs\n",
    "\n",
    "    return results\n",
    "\n",
    "def get_answer(query: str, pdf_path: str, groq_api_key: str) -> str:\n",
    "    \"\"\"Retrieve the most relevant documents using sub-queries and generate an answer.\"\"\"\n",
    "    retrieved_results = retrieve_results(query, pdf_path)\n",
    "    doc_context = '\\n---\\n'.join([\n",
    "        f\"Sub-Query: {sub_query}\\nResults:\\n\" + '\\n'.join([doc.page_content for doc in docs if doc.page_content.strip()])\n",
    "        for sub_query, docs in retrieved_results.items()\n",
    "    ])\n",
    "    \n",
    "    prompt = PromptTemplate(template=\"\"\"\n",
    "        You are an intelligent chatbot answering legal document-related queries.\n",
    "        Answer accurately using only the provided sub-queries and their corresponding answers given as contexts.\n",
    "        If no relevant information is found, state that no relevant information is available.\n",
    "\n",
    "        CONTEXT: {context}\\nQUESTION: {question}\\nFINAL ANSWER:\n",
    "    \"\"\", input_variables=[\"context\", \"question\"])\n",
    "\n",
    "    return LLMChain(llm=ChatGroq(groq_api_key=groq_api_key, model='llama3-70b-8192', temperature=0.05), prompt=prompt).run(context=doc_context, question=query)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
